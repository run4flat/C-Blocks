May 8
=====

I have a number of things working nicely with C::Blocks. One thing that is not
working is shared symbol tables, as demonstrated with the simple test called
05-shared.t

The problem in that test is that I get a segfault. The segfault does not occur
during compilation, but during runtime. This is rather odd. Preliminary
investigation has revealed that the compiler is *not* looking up symbols in the
extended symbol tables, so I would have expected to get a number of compilation
errors. Furthermore, the test shows that the segfault occurs even before the
first printf can display its message.

Here's the first interesting bit: if I comment-out the call to the function
defined in the clex block, it runs without segfaulting. Since this might be
some issue with defaulting to a signature of int func(int), and since print_ok
does not have that signature, I tried the int-int form and still go segfaults.
This suggests that the presence of the unknown and undeclared symbol print_ok
somehow screws up the pointer accounting in the compilation unit.

A simple test for how easy, or not, it is to cause this complication is to
simply add a call to the (yet undeclared) print_ok function, and see if it
breaks the original block. Apparently it does! This suggests that tcc is making
some assumption about the function for me. Perhaps this can be solved by
setting an appropriate flag.

After digging around, I realized I could use tcc_set_options to set the various
compiler options. The first string that I tried, "-Wall", solved the problem by
warning upon encountering the undeclared printf function. Although it was only
a warning, the error handling system caught the problem because it does not
differentiate between a warning and an error. At some point I need to add more
flexible configuration management. I also need to add a way to link to external
libraries, such as libperl.

The simplest mechanism to handle library linking is to provide a hints hash
mechanism, along with an api to play with the hints hash mechanism. Note that
this need not be through the keywords API. It could be through the use
mechanism, i.e. "use C::Blocks -I => '/usr/inc/', -L => '...', -l => '...';"
For now, I could allow these to accumulate, and I could later add a module for
greater manipulation (i.e. removal of items from the list, for example) or
automation when the time comes.

May 9
=====

Today I will try to implement the pulling-in of libperl. I expect that this
will involve compiling Perl's header files (eventually caching and loading that
to speed things up) and adding the library to the TCCState. This will likely
involve expanding the stream of pointers that gets copied among the hint hash
entries.

May 10
======

I thought quite a bit about how to implement the idea posed above. The problem
is that TCC does not know how to link against libraries on Mac OS, so I need to
use some alternative mechanism to pull in symbols. The simplest approach is to
use Dynaloader to load the library and retrieve symbols as needed. The folder
to include is under "$Config{archlib}/CORE", and libperl is called
"$Config{archlib}/CORE/$Config{libperl}". Dynaloader may only provide a Perlish
interface, but that is C accessible and does not intrinsically make it slow, by
any means.

So, I think I will write a C function that loads a library by calling
Dynaloader, through Perl, and another C function that loads symbols from a
library through Dynaloader, again through Perl. If there are ways to speed up
this process, they can be worked out after the first hack has been achieved.
This approach will work cross platform (even for systems that TCC knows how to
link against) and is a nice starting point.

May 20
======

It's been quite some time since that entry. During that time I have managed to
get the extended symbol table handling to work on Linux and Mac. Presumably, it
also works on Windows, but I have encountered problems including perl.h in a
Strawberry environment. The problems are due to the use of mingw header files
that have special cased behavior for different compilers. Sometimes, that
special cased behavior does not have an acceptable default, and the code issues
an #error. tcc dutifully throws them. I just realized that one possible way
around this is to try to compile Perl on Windows to see if Perl's configuration
script can figure out the correct parameters. If so, I could use those for the
compiler context.

Things that need to happen include:

  1)  Get perl.h to compile on mingw/Strawberry. [done]
  2)  Refactor the C code so it is easier to follow.
  3)  Implement a hash table for token-by-name lookup.
  4)  Write the lookup table caching, especially important for libperl
  5)  Improve the behavior and interface of cuse.

I managed to tackle the first item on that list. The very first Test::More
statement of the libperl test passes on Strawberry, but then it immediately
segfaults.

May 21
======

I have revised how libperl is detected; it is now more robust.

I then decided to revise how the test suite is written and have opted to
provide a rudimentary pair of functions to communicate between C and Perl
without needing to load libperl. This lets me disentangle cblocks trouble from
libperl trouble.

The result is that the initial test now runs and passes on Mac using perlbrew
v5.18, Windows XS using Strawberry v5.18, and Debian using the system Perl
v5.14 together with local::lib. The libperl tests fail on Windows.

I then revised the clex tests and uncovered something quite interesting. These
tests pass on Windows but fail on Mac. On Mac, I occasionally get "Internal
error: unable to locate extended symbol" but frequently I just get a
segmentation fault.

I decided to write a bit of bootstrapping code into Build.PL so that new
developers can simply type "perl Build.PL" and be guided through the
installation of whatever is needed. It is now time to recruit.

## Idea for caching and retrieving large libraries

The biggest problem with the header files associated with libperl is that the
symtab copy function runs in N**2 time. The second biggest problem with the
header files is that the copied symtab takes up about 5MB of ram. By
calculating the symtab once and caching it to disk, I can prevent the N**2
runtime of the copy function, but I still have to load 5MB of memory from disk.
The vast majority of that extended symbol table will not be used in any given
script. In all likelihood, the same handful of tokens will be used repeatedly.
Why take the time and ram to load all of it?

A better idea is to work with a couple of hashtables. The first one is
serialized along with the extended symbol table. It simply maps names to seek
positions in the file where the associated TokenSym data is located. (In fact,
if the key for the hash table is the name, the serialized data at the location
indicated by the value need only be the part of the TokenSym that does not
include the name, which has a well defined size. In that case, we only need to
associate the index of the TokenSym, which uses fewer bytes. :-) Having loaded
the hashtable and associated Syms from disk, we would add the TokenSym to a
second hashtable that points to our loaded data. This would be a fast cache for
frequently used tokens.

May 22
======

I have worked quite a bit on the lexical block tests, both in C::Blocks' test
suite and in tcc's extended symbol table test suite. tcc's extended symbol
table test suite seems to have no trouble with the tests on Linux and Mac, but
it gives trouble with most of the 40s series tests on Windows. When I turn
attention to the C::Blocks tests, I get passing behavior on all platforms for
tests 1, 2, and 3. Test #4 covers libperl and it works on Linux and Mac but
does not get very far on Windows. Every platform fails to pass test 10, the
first test that uses clex (but the second test that uses cshare).

Those led me to write a number of new tests for exsymtab handling in tcc,
those in the higher 40s, and to write a script to invoke those tests on
Windows. Until now, running those tests has been tricky.

I can now say that Windows encounters trouble with the exsymtab tests in the
upper 40s. I do not yet know why. In contrast, Linux and Mac both seem to be
fine with those tests.

The test that fails for Mac and Linux is #10, the one that uses the lexical
block. I decided to expand this test and figure out precisely what was going
on. In the new expanded test, I see that

  1) repeated invocations of a lexically-defined function might fail
  2) it seems to fail if the function uses a string constant
  3) it succeeds if the function uses a caller-provided variable

This suggests that the data section of the machine code that stores the string
constant might be getting corrupted after or because of the function
invocation.

To test this hypothesis, I modified _c_blocks_send_msg to print out the
received string and the pointer address. For compile-time constants, such as
the string "Hello!", the message and the address of the message should be the
same.

The test results indicate that the actual address sent into _c_blocks_send_msg
is incorrect. For one run, the reported address of the string "Hello!" was
0x98a4840; later when the same function using the same constant was invoked by
a different cblock, the reported address was 0xbf86f378.

Thus, on Linux and Mac at least, I can be fairly confident that something is
getting messed up with the baked-in addresses of constants when the compiler
context gets shared.

The frustrating aspect of the whole problem is that I cannot seem to produce a
basic test of tcc that reproduces this error.

However, I seem to be getting closer. As I walked home this evening I realized
that I have focused on sharing function declarations and definitions. I have
not done much with structs. To shed some light on the behavior of structs, I
decided to define a struct layout in a lexical block and then use it in two
succeeding cblocks. The resulting code is given in test 12.

Tests on both Mac and Windows croak after the 11th subtest of test 12. That is,
they fail when they try to actually execute the code in the second cblock that
would modify the struct based on the ttruct layout. They crash with a segfault.
Unfortunately, debugging stabs are not available for jit-compiled code, so I
can't pick it apart after the fact using gdb.

May 23
======

Last night I realized that I could examine the symbol table structures and make
a direct comparison between how a function definition and a function
declaration are stored in the symbol table. I will set this up as a test in the
tcc extended symtab tests and see what I get.

I added tests, but didn't uncover anything.

May 25
======

Although it seemed like a long shot, I decided that I should run an additional
test on tcc to see if dependent compilers states actually modified the elements
of extended symbol tables. Lo! they do! In particular, functions that are in
extended symbol tables are modified to have their c fields set!

May 26
======

In light of yesterday's findings, I extended the behavior of add_identifier()
and apply_and_clear_identifiers() so that they store and restore the value of
the c field for any identifier that needs to be added to a dependent
compilation unit.

December 15, 2014
=================

I have spent prodigious amounts of work rewriting how tcc handles its extended
symbol tables, to avoid some of the problems highlighted in the tests of this
distribution. I now have something that seems to be working on the tcc-side, so
I finally resume testing on the C::Blocks side.

As of this time of writing, the following tests pass: 01, 02, 03, 10, 12, 99.
Test 04-libperl.t fails, claiming it is unable to load static library libperl.a.
Test 13-clex-struct.t fails with a segfault. Tests 15 and 80 both use libperl,
so I can't speak to them.

All of this is possible because I added new developer functionality that lets me
specify the install location for tcc. This is useful for fast testing iterations
on tcc itself, without having to use an Alien::TinyCC install cycle.

December 19, 2014
=================

Having dug around the libperl module a bit, I had decided it is time to refactor
the enormous my_keyword_plugin() in Blocks.xs.

To begin, I wrote add_predeclaration_macros_to_block. Passes tests 1, 2, 3, 10,
12, and 99.

December 31, 2014
=================

I finished refactoring, then turned to debugging test 13 before changing how
libperl works. That led to a bug found and squashed in tccexsymtab. I have now
revised test 13, as well as test 15, so that they both test nontrivial things
and pass! Now, passing tests include 1, 2, 3, 10, 12, 13, 15, and 99!.

I am now in a position to revise the library handling, and libperl test.

January 1, 2015
===============

But before getting to libperl stuff, I decided to test out the lexical scoping
of declarations in clex blocks. This led me to write a number of tests which
revealed a subtle problem with how I was modifying the hints hash. I also seem
to have uncovered an even more subtle bug in tccexsymtab, as test 11 sometimes
crashes with a segmentation fault. That will be handled upstream. The most
important result is that when a function is not declared, it gets a *warning*,
not an error:

  implicit declaration of function '<name>'

To fix this, I changed the code that throws errors and warnings to search for
that phrase and replace it with "error: undeclared function '<name'>". After
fixing the test to search for the correct croak string, everything works!
