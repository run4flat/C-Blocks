May 8
=====

I have a number of things working nicely with C::Blocks. One thing that is not
working is shared symbol tables, as demonstrated with the simple test called
05-shared.t

The problem in that test is that I get a segfault. The segfault does not occur
during compilation, but during runtime. This is rather odd. Preliminary
investigation has revealed that the compiler is *not* looking up symbols in the
extended symbol tables, so I would have expected to get a number of compilation
errors. Furthermore, the test shows that the segfault occurs even before the
first printf can display its message.

Here's the first interesting bit: if I comment-out the call to the function
defined in the clex block, it runs without segfaulting. Since this might be
some issue with defaulting to a signature of int func(int), and since print_ok
does not have that signature, I tried the int-int form and still go segfaults.
This suggests that the presence of the unknown and undeclared symbol print_ok
somehow screws up the pointer accounting in the compilation unit.

A simple test for how easy, or not, it is to cause this complication is to
simply add a call to the (yet undeclared) print_ok function, and see if it
breaks the original block. Apparently it does! This suggests that tcc is making
some assumption about the function for me. Perhaps this can be solved by
setting an appropriate flag.

After digging around, I realized I could use tcc_set_options to set the various
compiler options. The first string that I tried, "-Wall", solved the problem by
warning upon encountering the undeclared printf function. Although it was only
a warning, the error handling system caught the problem because it does not
differentiate between a warning and an error. At some point I need to add more
flexible configuration management. I also need to add a way to link to external
libraries, such as libperl.

The simplest mechanism to handle library linking is to provide a hints hash
mechanism, along with an api to play with the hints hash mechanism. Note that
this need not be through the keywords API. It could be through the use
mechanism, i.e. "use C::Blocks -I => '/usr/inc/', -L => '...', -l => '...';"
For now, I could allow these to accumulate, and I could later add a module for
greater manipulation (i.e. removal of items from the list, for example) or
automation when the time comes.

May 9
=====

Today I will try to implement the pulling-in of libperl. I expect that this
will involve compiling Perl's header files (eventually caching and loading that
to speed things up) and adding the library to the TCCState. This will likely
involve expanding the stream of pointers that gets copied among the hint hash
entries.

May 10
======

I thought quite a bit about how to implement the idea posed above. The problem
is that TCC does not know how to link against libraries on Mac OS, so I need to
use some alternative mechanism to pull in symbols. The simplest approach is to
use Dynaloader to load the library and retrieve symbols as needed. The folder
to include is under "$Config{archlib}/CORE", and libperl is called
"$Config{archlib}/CORE/$Config{libperl}". Dynaloader may only provide a Perlish
interface, but that is C accessible and does not intrinsically make it slow, by
any means.

So, I think I will write a C function that loads a library by calling
Dynaloader, through Perl, and another C function that loads symbols from a
library through Dynaloader, again through Perl. If there are ways to speed up
this process, they can be worked out after the first hack has been achieved.
This approach will work cross platform (even for systems that TCC knows how to
link against) and is a nice starting point.

May 20
======

It's been quite some time since that entry. During that time I have managed to
get the extended symbol table handling to work on Linux and Mac. Presumably, it
also works on Windows, but I have encountered problems including perl.h in a
Strawberry environment. The problems are due to the use of mingw header files
that have special cased behavior for different compilers. Sometimes, that
special cased behavior does not have an acceptable default, and the code issues
an #error. tcc dutifully throws them. I just realized that one possible way
around this is to try to compile Perl on Windows to see if Perl's configuration
script can figure out the correct parameters. If so, I could use those for the
compiler context.

Things that need to happen include:

  1)  Get perl.h to compile on mingw/Strawberry. [done]
  2)  Refactor the C code so it is easier to follow.
  3)  Implement a hash table for token-by-name lookup.
  4)  Write the lookup table caching, especially important for libperl
  5)  Improve the behavior and interface of cuse.

I managed to tackle the first item on that list. The very first Test::More
statement of the libperl test passes on Strawberry, but then it immediately
segfaults.

May 21
======

I have revised how libperl is detected; it is now more robust.

I then decided to revise how the test suite is written and have opted to
provide a rudimentary pair of functions to communicate between C and Perl
without needing to load libperl. This lets me disentangle cblocks trouble from
libperl trouble.

The result is that the initial test now runs and passes on Mac using perlbrew
v5.18, Windows XS using Strawberry v5.18, and Debian using the system Perl
v5.14 together with local::lib. The libperl tests fail on Windows.

I then revised the clex tests and uncovered something quite interesting. These
tests pass on Windows but fail on Mac. On Mac, I occasionally get "Internal
error: unable to locate extended symbol" but frequently I just get a
segmentation fault.

I decided to write a bit of bootstrapping code into Build.PL so that new
developers can simply type "perl Build.PL" and be guided through the
installation of whatever is needed. It is now time to recruit.

## Idea for caching and retrieving large libraries

The biggest problem with the header files associated with libperl is that the
symtab copy function runs in N**2 time. The second biggest problem with the
header files is that the copied symtab takes up about 5MB of ram. By
calculating the symtab once and caching it to disk, I can prevent the N**2
runtime of the copy function, but I still have to load 5MB of memory from disk.
The vast majority of that extended symbol table will not be used in any given
script. In all likelihood, the same handful of tokens will be used repeatedly.
Why take the time and ram to load all of it?

A better idea is to work with a couple of hashtables. The first one is
serialized along with the extended symbol table. It simply maps names to seek
positions in the file where the associated TokenSym data is located. (In fact,
if the key for the hash table is the name, the serialized data at the location
indicated by the value need only be the part of the TokenSym that does not
include the name, which has a well defined size. In that case, we only need to
associate the index of the TokenSym, which uses fewer bytes. :-) Having loaded
the hashtable and associated Syms from disk, we would add the TokenSym to a
second hashtable that points to our loaded data. This would be a fast cache for
frequently used tokens.
